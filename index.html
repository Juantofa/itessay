<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>Juan Torres - Essay</title>
    <!-- Favicon-->
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="css/styles.css" rel="stylesheet" />
</head>

<body>
    <!-- Header - set the background image for the header in the line below-->
    <header class="py-5 bg-image-full"
        style="background-image: url('https://www.blognone.com/sites/default/files/externals/bd20374223f29d4d268fc7c4f4aef044.png')">
        <div class="text-center my-5">
            <br>
            <br>
        </div>
    </header>
    <!-- Content section-->
    <section class="py-5">
        <div class="container my-5">
            <div class="row justify-content-center">
                <div class="col-lg-6">
                    <h2>Why has GPT-3 became so important lately?</h2>
                    <p class="lead">by Juan Manuel Torres Farfán</p>
                    <p class="mb-0">Artificial Intelligence (AI) are systems or machines that try to imitate humans’
                        intelligence. Their purpose is to perform tasks while they learn through all the information
                        that can collect. There are two concepts that can be confused with Artificial Intelligence:
                        Machine Learning and Deep Learning. It is important to know that are not the same, although all
                        machine learning is AI, not all AI is machine learning (Oracle, 2022). GPT-3 is the most recent
                        AI model developed by OpenAI, it is an Artificial Intelligence that is able to generate content
                        using humans’ natural language in a similar way to a human would, through a simple request put
                        in human words easy to request.</p><br>
                    <p class="mb-0">GPT-3 is the third version of GPT (Generative Pre-trained Transformer) developed by
                        OpenAI. OpenAI is a non-profit search organization founded in 2015 that received US$1 billion
                        from some companies, including Tesla, to start working. In 2019 they announced that Microsoft
                        was going to invest another billion on them during the next decade and shortly after they
                        obtained an exclusive license of GPT-3. Although they obtained an exclusive license, this does
                        not mean that they are going to be the only ones with this, the model is still going to be
                        public. Nowadays Microsoft has created a new service called Azure OpenAI which allows users to
                        access to OpenAI’s API through the Azure portal (Microsoft, 2021).</p><br>
                    <p class="mb-0">GPT-3 is a data-driven trained model that can imitate the natural language patterns
                        of humans nearly perfectly thanks to the amount of Internet text data and to the thousands of
                        books that trained the model (Zhang, M. Li, J. 2021). Compared to its previous version, GPT-2,
                        this version it’s a lot better. Just to give some numbers, 2nd-generation parameters used 1.5
                        billion learning parameters, while 3rd-generation uses 175 billion learning parameters and data
                        scale grew from 40GB to 45TB, making this generation the largest language ever created. Compared
                        to GPT-2, this generation has achieved excellent results on numerous new tasks, including
                        mathematical addition, news article generation, vocabulary interpretation, and code writing
                        (Zhang, M. Li, J. 2021).</p><br>
                    <p class="mb-0">Its main use, which is where it performs the best, is to produce and write quality
                        texts just by introducing a simple keyword or a sentence explaining what is needed. It is like a
                        search made in Google and works in a similar way, it queries the search made and shows some
                        results related to what is searched, however, GPT-3 can connect these results, difficult or not,
                        reasonable or unreasonable, and build a meaningful, understandable and well-connected text easy
                        to read.</p><br>
                    <p class="mb-0">Another use that GPT-3 offers is the possibility to generate code of something
                        wanted just by explaining very specifically what is needed and it is going to give you a code
                        that can do what you specified. An example of this is “debuild.co” that generates ReactJS code
                        just by putting specifically what you need and gives you the code and an example of the code
                        does.
                        Someone did a Figma plugin where you can write a design you want to have or edit and the plugin
                        by its own way develops and design what you wanted. There is also an application called
                        FitnessAI that uses this model to give recommendations and answer questions about fitness. These
                        are only examples that shows the capacity of the model and that it can be used in many ways, not
                        only to write texts or to create intelligent chatbots that are the principal uses that it
                        offers.
                    </p><br>
                    <p class="mb-0">Leaving aside the way how it works when it is processing the requests, the way it
                        can be used is very simple. It can be said that this model applies the KISS (Keep it Simple
                        Stupid) principle, anyone can use a GPT-3 application.</p><br>
                    <p class="mb-0">Having seen what it can do, it is important to mention that it has some problems and
                        limitations too. For example, when the text that its writing is very long, it starts to repeat
                        some the ideas that mentioned before and write things without coherence and nonsensical phrases.
                        Another thing that tends to happen is that sometimes the information may not correspond to the
                        truth, and having this in mind, it can make it lose credibility. Another problem is that
                        training and hosting this model needs a lot of resources that at the end of the day are also
                        very expensive.</p><br>
                    <p class="mb-0">Even having its problems, it is important to remember that this model was presented
                        in 2020 and still have a lot to improve, but the results that has been giving are very
                        impressive and worthy of admiration. </p><br>
                    <p class="mb-0">In conclusion GPT-3 is an incredible Artificial Intelligence model that offers a lot
                        of possibilities just by requesting something in human words. From writing good and coherent
                        texts (when the length requested is not so long), to develop applications or plugins for
                        applications that are already being used. Although this model is very good at the moment, it has
                        its problems too, but as mentioned before, due to the performance and the results that has given
                        having less than two years of being presented (time that is very short to have a big development
                        with the model) it can be easily seen that this model is very well trained and has some things
                        to improve. However, is a great improvement against its previous version and yet with its
                        problems is very useful and is being used nowadays as the examples showed. </p><br><br>
                    <p class="mb-0">[1] Floridi, L. and Chiriatti, M., 2020. GPT-3: Its Nature, Scope, Limits, and
                        Consequences. Minds and Machines, 30(4), pp.681-694. </p>
                    <p class="mb-0">[2] Dale, R. (2021). GPT-3: What’s it good for? Natural Language Engineering, 27(1),
                        113-118. doi:10.1017/S1351324920000601 </p>
                    <p class="mb-0">[3] Zhang, M. and Li, J., 2021. A commentary of GPT-3 in MIT Technology Review 2021.
                        Fundamental Research, 1(6), pp.831-833.</p>
                    <p class="mb-0"> </p><br>
                </div>
            </div>
        </div>
    </section>
    <footer class="py-5 bg-dark">
        <div class="container">
            <p class="m-0 text-center text-white">Juan Manuel Torres</p>
            <p class="m-0 text-center text-white">Ingeniería Informática - Universidad de La Sabana</p>
            <p class="m-0 text-center text-white">2021</p>
        </div>
    </footer>
    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
</body>

</html>